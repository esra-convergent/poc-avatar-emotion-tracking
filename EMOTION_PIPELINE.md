# Emotion Detection Pipeline - Complete Flow

This document shows the **complete end-to-end flow** of how emotions are detected, analyzed, sent, and displayed in the voice AI application.

---

## ğŸ¯ Overview

The emotion system analyzes **ONLY user speech** (not agent responses) and displays the agent's "reaction face" as an emoji. The emoji represents how the agent is reacting to the user's emotional state.

---

## ğŸ“Š Complete Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER SPEAKS                                  â”‚
â”‚                   "I'm so happy today!"                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Speech-to-Text (STT)                                        â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Service: AssemblyAI Universal Streaming                           â”‚
â”‚ â€¢ Location: Python Agent (agent.py:98)                              â”‚
â”‚ â€¢ Input: Audio stream from user's microphone                        â”‚
â”‚ â€¢ Output: Text transcript "I'm so happy today!"                     â”‚
â”‚ â€¢ Timing: ~500ms after user stops speaking                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: LLM Processing                                              â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Service: OpenAI GPT-4.1-mini                                      â”‚
â”‚ â€¢ Location: Python Agent (agent.py:101)                             â”‚
â”‚ â€¢ Input: User transcript                                            â”‚
â”‚ â€¢ Process: LLM generates response                                   â”‚
â”‚ â€¢ Output: Agent response text                                       â”‚
â”‚ â€¢ Timing: 1-3 seconds (depending on response complexity)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Conversation Item Added Event                               â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Event: "conversation_item_added"                                  â”‚
â”‚ â€¢ Location: Python Agent (agent.py:120)                             â”‚
â”‚ â€¢ Triggered: When user message is added to conversation history     â”‚
â”‚ â€¢ Data: event.item contains message with content and role           â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Handler: on_conversation_item()                                   â”‚
â”‚   â”œâ”€ Check if message has content                                   â”‚
â”‚   â”œâ”€ Get message.role ("user" or "assistant")                       â”‚
â”‚   â”œâ”€ SKIP if role == "assistant" (don't analyze agent's own text)  â”‚
â”‚   â”œâ”€ Handle content as list or string                               â”‚
â”‚   â””â”€ Extract transcript text                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Emotion Analysis (Keyword Matching)                         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Service: EmotionAnalyzer (keyword-based)                          â”‚
â”‚ â€¢ Location: python-agent/src/emotion_analyzer.py                    â”‚
â”‚ â€¢ Input: "I'm so happy today!"                                      â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Process Flow:                                                     â”‚
â”‚   1. Convert text to lowercase: "i'm so happy today!"               â”‚
â”‚   2. Check keywords in ORDER (first match wins):                    â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚      â”‚ Order  Emotion    Keywords Checked                       â”‚  â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚      â”‚  1st   angry      fuck, angry, hate, mad, pissed...      â”‚  â”‚
â”‚      â”‚  2nd   sad        sad, depressed, down, unhappy...       â”‚  â”‚
â”‚      â”‚  3rd   anxious    worried, anxious, scared, afraid...    â”‚  â”‚
â”‚      â”‚  4th   grateful   thank, thanks, appreciate, grateful... â”‚  â”‚
â”‚      â”‚  5th   surprised  wow, surprised, shocked, omg...        â”‚  â”‚
â”‚      â”‚  6th   happy      happy, great, awesome, love...  âœ“      â”‚  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   3. Found "happy" keyword in text                                  â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Output: "happy"                                                   â”‚
â”‚ â€¢ Timing: <10ms (instant keyword lookup)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Send Emotion Data                                           â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Function: send_emotion_data()                                     â”‚
â”‚ â€¢ Location: Python Agent (agent.py:67-82)                           â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Data Structure Created:                                           â”‚
â”‚   {                                                                  â”‚
â”‚     "type": "emotion",                                              â”‚
â”‚     "emotion": "happy",                                             â”‚
â”‚     "source": "agent",  // Agent's reaction to user                 â”‚
â”‚     "text": "I'm so happy today!",                                  â”‚
â”‚     "timestamp": 1735041234567,  // milliseconds                    â”‚
â”‚     "confidence": 1.0                                               â”‚
â”‚   }                                                                  â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Transport Method: LiveKit Participant Attributes                  â”‚
â”‚   - Method: room.local_participant.set_attributes()                 â”‚
â”‚   - Key: "emotion"                                                  â”‚
â”‚   - Value: JSON string of emotion data                              â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Timing: <50ms (async task, non-blocking)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NETWORK TRANSMISSION                              â”‚
â”‚                  (LiveKit WebRTC signaling)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Frontend Receives Emotion                                   â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Hook: useEmotionData()                                            â”‚
â”‚ â€¢ Location: hooks/useEmotionData.ts                                 â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Event Listener Setup (line 129):                                  â”‚
â”‚   session.room.on(                                                  â”‚
â”‚     RoomEvent.ParticipantAttributesChanged,                         â”‚
â”‚     handleAttributesChanged                                         â”‚
â”‚   )                                                                  â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Handler Flow (lines 58-77):                                       â”‚
â”‚   1. Event fires with changedAttributes object                      â”‚
â”‚   2. Check if changedAttributes.emotion exists                      â”‚
â”‚   3. Parse JSON: JSON.parse(changedAttributes.emotion)              â”‚
â”‚   4. Call processEmotionData(data)                                  â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Timing: <100ms (event propagation + parsing)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: Process & Update State                                      â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Function: processEmotionData()                                    â”‚
â”‚ â€¢ Location: hooks/useEmotionData.ts (lines 80-123)                  â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Processing Steps:                                                 â”‚
â”‚   1. Validate data has emotion and source                           â”‚
â”‚   2. Normalize timestamp (handle seconds vs milliseconds)           â”‚
â”‚   3. Create EmotionData object                                      â”‚
â”‚   4. Update React state via setEmotionState()                       â”‚
â”‚                                                                      â”‚
â”‚ â€¢ State Update Logic (lines 104-119):                               â”‚
â”‚   - If source === "agent": Update agentEmotion = "happy"           â”‚
â”‚   - If source === "user": Update userEmotion                        â”‚
â”‚   - Add to history array (keep last 50 items)                       â”‚
â”‚   - Update lastUpdate timestamp                                     â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Result: Component re-renders with new emotion                     â”‚
â”‚ â€¢ Timing: <50ms (React state update)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: Emoji Display Updates                                       â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ â€¢ Component: EmotionDisplay                                         â”‚
â”‚ â€¢ Location: components/app/emotion-display.tsx                      â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Render Flow:                                                      â”‚
â”‚   1. Receives prop: emotion="happy"                                 â”‚
â”‚   2. Look up config: EMOTION_CONFIG["happy"]                        â”‚
â”‚      {                                                               â”‚
â”‚        emoji: "ğŸ˜Š",                                                  â”‚
â”‚        color: "#10b981", // green                                   â”‚
â”‚        label: "Happy"                                               â”‚
â”‚      }                                                               â”‚
â”‚   3. Trigger re-animation (useEffect on emotion change)             â”‚
â”‚   4. Render with Framer Motion animations                           â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Animation (lines 54-78):                                          â”‚
â”‚   - Initial: scale=0, opacity=0                                     â”‚
â”‚   - Animate: scale=1.1, rotate=5, opacity=1                         â”‚
â”‚   - Transition: Spring animation (stiffness=300, damping=25)        â”‚
â”‚                                                                      â”‚
â”‚ â€¢ Visual Result: ğŸ˜Š appears with bounce/rotate animation            â”‚
â”‚ â€¢ Timing: ~300ms animation duration                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER SEES EMOJI: ğŸ˜Š                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## â±ï¸ Total Timing Breakdown

| Step | Process | Typical Duration |
|------|---------|------------------|
| 1 | STT Transcription | ~500ms |
| 2 | LLM Processing | 1-3 seconds |
| 3 | Event Trigger | <10ms |
| 4 | Emotion Analysis | <10ms |
| 5 | Send via Attributes | <50ms |
| 6 | Network + Event Handling | ~100ms |
| 7 | React State Update | <50ms |
| 8 | Animation Render | ~300ms |
| **TOTAL** | **End-to-End Latency** | **~2-4 seconds** |

**Note**: The main delay (1-3 seconds) is from the LLM processing the user's message. The emotion analysis itself is instant (<10ms), but we have to wait for the `conversation_item_added` event which fires after LLM processing.

---

## ğŸ”§ Technical Details

### Why Use `conversation_item_added` Event?

The event fires when a conversation item (user or agent message) is added to the conversation history. This happens:

- **For user messages**: After STT transcription AND LLM starts processing
- **For agent messages**: After LLM generates the response

We filter to ONLY process user messages (skip when `role === "assistant"`).

### Why Not Use Earlier Events?

Earlier events like `user_transcript_received` or `user_speech_committed` don't work reliably in the current LiveKit Agents SDK version (1.3.9) when using the `AgentSession` pipeline architecture.

### Data Transport: Why Participant Attributes?

**Participant Attributes** are the recommended way to send custom metadata in LiveKit:
- âœ… Automatically synchronized across all participants
- âœ… Triggers `ParticipantAttributesChanged` events
- âœ… Persists during the session
- âœ… Works with local participant (agent can send to itself)

**Data Channel** would require:
- âŒ Manual message routing
- âŒ Doesn't work for local participant loopback
- âŒ More complex event handling

---

## ğŸ“ File Reference Map

| File | Purpose | Key Functions/Components |
|------|---------|-------------------------|
| `python-agent/src/agent.py` | Main agent logic, STT, LLM, emotion hooks | `my_agent()`, `on_conversation_item()`, `send_emotion_data()` |
| `python-agent/src/emotion_analyzer.py` | Keyword-based emotion detection | `EmotionAnalyzer.analyze()`, `EMOTION_KEYWORDS` |
| `hooks/useEmotionData.ts` | React hook to receive and process emotions | `useEmotionData()`, `handleAttributesChanged()`, `processEmotionData()` |
| `lib/emotion-types.ts` | TypeScript types and emoji config | `EmotionType`, `EmotionData`, `EMOTION_CONFIG` |
| `components/app/emotion-display.tsx` | Animated emoji display component | `EmotionDisplay` |
| `components/app/emotion-test-panel.tsx` | Debug panel for manual testing | `sendTestEmotion()` |

---

## ğŸ¨ Emotion Configuration

Each emotion has configuration in `lib/emotion-types.ts`:

```typescript
{
  happy: {
    emoji: 'ğŸ˜Š',
    color: '#10b981', // green
    label: 'Happy',
  },
  sad: {
    emoji: 'ğŸ˜¢',
    color: '#3b82f6', // blue
    label: 'Sad',
  },
  // ... etc
}
```

---

## ğŸ” Debugging the Pipeline

### Python Agent Logs

```bash
# Start the agent with logging
cd python-agent
uv run python src/agent.py dev
```

Look for these log messages:
1. `Setting up emotion analysis hooks...` - Hooks initialized
2. `âœ… Emotion hooks registered` - Ready to detect
3. `ğŸ­ USER said: <text>` - User message received
4. `ğŸ­ Agent's REACTION emotion: <emotion>` - Emotion detected
5. `ğŸ“¤ Sent emotion via attributes: <emotion> (agent)` - Sent to frontend

### Browser Console Logs

Look for these console messages:
1. `âœ… Emotion data listener attached` - Hook is listening
2. `ğŸ”” ATTRIBUTES CHANGED:` - Received attribute change
3. `âœ… EMOTION from ATTRIBUTES:` - Parsed emotion data
4. `ğŸ­ Processing emotion:` - Updating state

### Common Issues

| Symptom | Likely Cause | Check |
|---------|--------------|-------|
| No emoji appears | Event handler not firing | Check Python logs for `ğŸ­ USER said` |
| Emoji doesn't update | Frontend not receiving | Check browser console for `ATTRIBUTES CHANGED` |
| Wrong emoji shows | Keyword mismatch | Check `emotion_analyzer.py` keyword order |
| Emoji updates slowly | LLM processing delay | Normal - emotion fires after LLM processes |

---

## ğŸš€ Performance Optimization

Current bottleneck: **LLM Processing (1-3 seconds)**

The emotion detection itself is nearly instant (<10ms keyword matching), but we're limited by when the `conversation_item_added` event fires, which is after LLM processing begins.

Potential future optimizations:
1. Use streaming STT with interim results
2. Hook into earlier pipeline events (if SDK supports it)
3. Run emotion analysis in parallel with LLM (requires different event)

---

## ğŸ“ Example Flow with Logs

**User says**: "I'm so happy today!"

**Python Terminal**:
```
DEBUG  livekit.agents  received user transcript {"user_transcript": "I'm so happy today!"}
INFO   agent           ğŸ­ USER said: I'm so happy today!
INFO   emotion_analyzer Detected emotion: happy in text: 'I'm so happy today!'
INFO   agent           ğŸ­ Agent's REACTION emotion: happy
INFO   agent           ğŸ“¤ Sent emotion via attributes: happy (agent) - I'm so happy today!
```

**Browser Console**:
```javascript
ğŸ”” ATTRIBUTES CHANGED: {emotion: '{"type":"emotion","emotion":"happy",...}'} from agent-xyz
âœ… EMOTION from ATTRIBUTES: {"type":"emotion","emotion":"happy","source":"agent",...}
ğŸ­ Processing emotion: {type: 'emotion', emotion: 'happy', source: 'agent', timestamp: 1735041234567}
```

**Visual Result**: ğŸ˜Š emoji appears with bounce animation

---

## ğŸ¯ Summary

The emotion pipeline is a **reactive system** that:

1. **Listens** to user speech
2. **Transcribes** it via STT (AssemblyAI)
3. **Waits** for LLM to process (OpenAI GPT-4.1-mini)
4. **Analyzes** the transcript for emotion keywords
5. **Sends** emotion data via LiveKit participant attributes
6. **Receives** it in React via event listeners
7. **Updates** React state
8. **Renders** animated emoji

The system is designed to be **stable** (only analyzes user text) and **visual** (agent's reaction face), making it perfect for a POC demonstration.
